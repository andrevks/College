{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LexicalAnalyser.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAlu1QgwmRBV"
      },
      "source": [
        "# Lexical Analyser\n",
        "\n",
        "Owner: André Geraldo \n",
        "\n",
        "Course: Computer Enginnering\n",
        "\n",
        "Steps:\n",
        "\n",
        "1- Read a file containing a source code with a specific syntax\n",
        "\n",
        "2 - User a buffer to take each line and classify them \n",
        "\n",
        "3 - Regex will recognise if a token is valid and store them\n",
        "\n",
        "4 - store each token in the the following format:\n",
        " [Token, Lexema, Line, Column]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtTM2UoAkwsI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cead080-82b0-4df2-b533-b82a046a3b74"
      },
      "source": [
        "#import of regex\n",
        "import re\n",
        "\n",
        "class Lexer:\n",
        "\n",
        "  def __init__(self, source_code):\n",
        "    #self.__especiais = ['+','/']\n",
        "    #self.__buffer = []\n",
        "    self.__source_code = source_code\n",
        "\n",
        "  def scanning(self):\n",
        "\n",
        "    buffer = self.__source_code\n",
        "    #defining the pattern\n",
        "    pattern = re.compile(r'funny')\n",
        "\n",
        "\n",
        "    matches = pattern.finditer(buffer)\n",
        " \n",
        "    print(\"\\nBuffer: \")\n",
        "    print(buffer)\n",
        "    print(\"\\n\")\n",
        "    for match in matches:\n",
        "      print(match)\n",
        "\n",
        "\n",
        "def main():\n",
        "  #read the current fun lang file in test.lang\n",
        "  # and store it in a buffer\n",
        "\n",
        "  content = \"\"\n",
        "  with open(\"lang.txt\", \"r\") as file:\n",
        "    content = file.read()\n",
        "\n",
        "  lex = Lexer(content)\n",
        "  tokens = lex.scanning()\n",
        "\n",
        "\n",
        "main()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Buffer: \n",
            "BeginFun\n",
            "  funny variable.\n",
            "  variable <- 10 * (124+666).\n",
            "EndFun\n",
            "\n",
            "\n",
            "<re.Match object; span=(11, 16), match='funny'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76qwRG0kGrI8",
        "outputId": "e2ac8319-aabe-4010-a271-d7e2ad90d64f"
      },
      "source": [
        "import re\n",
        "\n",
        "text_to_search = '''\n",
        "BeginFun\n",
        "  funny variable.\n",
        "  variable <- 10 * (124+ 666).\n",
        "EndFun\n",
        "\n",
        "'''\n",
        "\n",
        "regexRules = '''\n",
        "\n",
        "'''\n",
        "pattern = re.compile(r'\\d+')\n",
        "\n",
        "matches = pattern.finditer(text_to_search)\n",
        "\n",
        "for match in matches:\n",
        "  print(match)\n",
        "\n",
        "print(text_to_search[12:17])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<re.Match object; span=(42, 44), match='10'>\n",
            "<re.Match object; span=(48, 51), match='124'>\n",
            "<re.Match object; span=(53, 56), match='666'>\n",
            "funny\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FjSMEHeplux",
        "outputId": "36560fc2-563a-494e-cb78-2b6da6419a63"
      },
      "source": [
        "subject = \"Data Science\"\n",
        "language = \"Python\"\n",
        "\n",
        "output_str = \"I am studying %s and using Python as the programming language.\" %subject \n",
        "\n",
        "print(output_str)\n",
        "\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I am studying Data Science and using Python as the programming language.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBuMC05MvwuF",
        "outputId": "e439cfd8-e17a-4dca-b6c5-7fb0211533fd"
      },
      "source": [
        "list1 = [('NUMBER', r'\\d+'),( 'ASSIGN',  r':=') ]\n",
        "list2 = [('NOME_TOKEN', r'REGEX_EXP'),('NOME_TOKEN2', r'REGEX_EXP2') ]\n",
        "token = \"|\".join('(?P<%s>%s)' % pair for pair in list1)\n",
        "\n",
        "\n",
        "\n",
        "print(token)\n",
        "\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?P<NUMBER>\\d+)|(?P<ASSIGN>:=)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Rd6KFjoGALN",
        "outputId": "68a5b043-df57-45e8-9821-8e502d621be2"
      },
      "source": [
        "from typing import NamedTuple\n",
        "import re\n",
        "\n",
        "\n",
        "class Token(NamedTuple):\n",
        "  type: str\n",
        "  value: str\n",
        "  line: int\n",
        "  column: int\n",
        "\n",
        "\n",
        "def tokenize(code):\n",
        "  keywords = {'BeginFun','EndFun','if','then','else','elif','end','funLoopWhile','do','endFunLoop',\n",
        "              'showMeTheCode','grabInput','funny'}\n",
        "  token_specification = [\n",
        "    ('TK_NUM', r'\\d+'),\n",
        "    ('TK_ATRIB', r'<-'),\n",
        "    ('TK_PERIOD', r'\\.'),\n",
        "    ('TK_ID', r'[A-Za-z]([A-Za-z]|\\d|_)*'),\n",
        "    ('TK_STRING', r'^\\\"([A-Za-z]|\\d|\\.|%|:| )*\\\"$'), #String com aspas\n",
        "    ('TK_OP_AR', r'[-+*\\/]'), #Oerações aritmética\n",
        "    ('TK_OP_RE', r'[=<>]|<>'),#Operação relacional  \n",
        "    ('TK_BOOL', r'[|&]'),       \n",
        "    ('TK_OPEN_P', r'\\('),\n",
        "    ('TK_CLOSE_P', r'\\)'),\n",
        "    ('TK_COMMA', r','),\n",
        "    ('TK_NEW_LINE',r'\\n'),\n",
        "    ('TK_SKIP', r'[\\ \\t\\r]+'),\n",
        "    ('MISMATCH', r'.'),                \n",
        "  ]            \n",
        "\n",
        "  tk_regex_rules = '|'.join('(?P<%s>%s)' % pair for pair in token_specification)\n",
        "\n",
        "  line_num = 1\n",
        "  line_start = 0\n",
        "  for mo in re.finditer(tk_regex_rules,code):\n",
        "    kind = mo.lastgroup\n",
        "    value = mo.group()\n",
        "    column = mo.start() - line_start\n",
        "    #print(\"LASTGROUP: \", kind)\n",
        "     #print(\"\\nVALUE: \", mo.group())\n",
        "    #print(\"\\nCOLLUMN: \", mo.start() - line_start)\n",
        "    if kind == 'TK_NUM':\n",
        "      value = int(value)\n",
        "    elif value in keywords :\n",
        "      kind = value\n",
        "    elif kind == 'TK_NEW_LINE':\n",
        "      line_start = mo.end()\n",
        "      line_num += 1\n",
        "      continue\n",
        "    elif kind == 'TK_SKIP':\n",
        "      continue\n",
        "    elif kind == 'MISMATCH':\n",
        "      raise RuntimeError(f'{value!r} unexpected on line {line_num}')\n",
        "    yield Token(kind,value, line_num, column)\n",
        "\n",
        "    \n",
        "code_source = '''\n",
        "BeginFun\n",
        "\n",
        " if idade < 10 & anoNasc <> 10 then\n",
        "\n",
        "\tfunLoopWhile valor_ethereum < valor_bitcoin do\n",
        "\n",
        "\t\tshowMeTheCode investYourMoney.\n",
        "\n",
        "\tendFunLoop.\n",
        "\n",
        " end.\n",
        " \n",
        "EndFun\n",
        "'''\n",
        "#tokenize(code_source)\n",
        "for token in tokenize(code_source):\n",
        "  print(token)\n"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token(type='BeginFun', value='BeginFun', line=2, column=0)\n",
            "Token(type='if', value='if', line=4, column=1)\n",
            "Token(type='TK_ID', value='idade', line=4, column=4)\n",
            "Token(type='TK_OP_RE', value='<', line=4, column=10)\n",
            "Token(type='TK_NUM', value=10, line=4, column=12)\n",
            "Token(type='TK_BOOL', value='&', line=4, column=15)\n",
            "Token(type='TK_ID', value='anoNasc', line=4, column=17)\n",
            "Token(type='TK_OP_RE', value='<', line=4, column=25)\n",
            "Token(type='TK_OP_RE', value='>', line=4, column=26)\n",
            "Token(type='TK_NUM', value=10, line=4, column=28)\n",
            "Token(type='then', value='then', line=4, column=31)\n",
            "Token(type='funLoopWhile', value='funLoopWhile', line=6, column=1)\n",
            "Token(type='TK_ID', value='valor_ethereum', line=6, column=14)\n",
            "Token(type='TK_OP_RE', value='<', line=6, column=29)\n",
            "Token(type='TK_ID', value='valor_bitcoin', line=6, column=31)\n",
            "Token(type='do', value='do', line=6, column=45)\n",
            "Token(type='showMeTheCode', value='showMeTheCode', line=8, column=2)\n",
            "Token(type='TK_ID', value='investYourMoney', line=8, column=16)\n",
            "Token(type='TK_PERIOD', value='.', line=8, column=31)\n",
            "Token(type='endFunLoop', value='endFunLoop', line=10, column=1)\n",
            "Token(type='TK_PERIOD', value='.', line=10, column=11)\n",
            "Token(type='end', value='end', line=12, column=1)\n",
            "Token(type='TK_PERIOD', value='.', line=12, column=4)\n",
            "Token(type='EndFun', value='EndFun', line=14, column=0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWyOjwFOWvIZ",
        "outputId": "12d2fb31-30a2-4d19-8934-835519217df4"
      },
      "source": [
        "from typing import NamedTuple\n",
        "import re\n",
        "\n",
        "class Token(NamedTuple):\n",
        "    type: str\n",
        "    value: str\n",
        "    line: int\n",
        "    column: int\n",
        "\n",
        "def tokenize(code):\n",
        "    keywords = {'IF', 'THEN', 'ENDIF', 'FOR', 'NEXT', 'GOSUB', 'RETURN'}\n",
        "    token_specification = [\n",
        "        ('NUMBER',   r'\\d+'),  # Integer or decimal number\n",
        "        ('ASSIGN',   r':='),           # Assignment operator\n",
        "        ('END',      r';'),            # Statement terminator\n",
        "        ('ID',       r'[A-Za-z]+'),    # Identifiers\n",
        "        ('OP',       r'[+\\-*/]'),      # Arithmetic operators\n",
        "        ('NEWLINE',  r'\\n'),           # Line endings\n",
        "        ('SKIP',     r'[ \\t]+'),       # Skip over spaces and tabs\n",
        "        ('MISMATCH', r'.'),            # Any other character\n",
        "    ]\n",
        "    tok_regex = '|'.join('(?P<%s>%s)' % pair for pair in token_specification)\n",
        "    print(\"REGEX: \", tok_regex)\n",
        "    line_num = 1\n",
        "    line_start = 0\n",
        "\n",
        "    for mo in re.finditer(tok_regex, code):\n",
        "        kind = mo.lastgroup\n",
        "        value = mo.group()\n",
        "        column = mo.start() - line_start\n",
        "        #print(\"LASTGROUP: \", mo.lastgroup)\n",
        "        print(\"\\nVALUE: \", mo.group())\n",
        "        #print(\"\\nCOLLUMN: \", mo.start() - line_start)\n",
        "        if kind == 'NUMBER':\n",
        "            value = int(value)\n",
        "        elif kind == 'ID' and value in keywords:\n",
        "            kind = value\n",
        "        elif kind == 'NEWLINE':\n",
        "            line_start = mo.end()\n",
        "            line_num += 1\n",
        "            continue\n",
        "        elif kind == 'SKIP':\n",
        "            continue\n",
        "        elif kind == 'MISMATCH':\n",
        "            raise RuntimeError(f'{value!r} unexpected on line {line_num}')\n",
        "        yield Token(kind, value, line_num, column)\n",
        "\n",
        "statements = '''\n",
        "   IF quantity THEN\n",
        "        total:=total-price*quantity;\n",
        "        tax := price * 5;\n",
        "    ENDIF;\n",
        "'''\n",
        "tokenize(statements)\n",
        "for token in tokenize(statements):\n",
        "    print(\"NADA HAVER: \",token)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "REGEX:  (?P<NUMBER>\\d+)|(?P<ASSIGN>:=)|(?P<END>;)|(?P<ID>[A-Za-z]+)|(?P<OP>[+\\-*/])|(?P<NEWLINE>\\n)|(?P<SKIP>[ \\t]+)|(?P<MISMATCH>.)\n",
            "\n",
            "VALUE:  \n",
            "\n",
            "\n",
            "VALUE:     \n",
            "\n",
            "VALUE:  IF\n",
            "NADA HAVER:  Token(type='IF', value='IF', line=2, column=3)\n",
            "\n",
            "VALUE:   \n",
            "\n",
            "VALUE:  quantity\n",
            "NADA HAVER:  Token(type='ID', value='quantity', line=2, column=6)\n",
            "\n",
            "VALUE:   \n",
            "\n",
            "VALUE:  THEN\n",
            "NADA HAVER:  Token(type='THEN', value='THEN', line=2, column=15)\n",
            "\n",
            "VALUE:  \n",
            "\n",
            "\n",
            "VALUE:          \n",
            "\n",
            "VALUE:  total\n",
            "NADA HAVER:  Token(type='ID', value='total', line=3, column=8)\n",
            "\n",
            "VALUE:  :=\n",
            "NADA HAVER:  Token(type='ASSIGN', value=':=', line=3, column=13)\n",
            "\n",
            "VALUE:  total\n",
            "NADA HAVER:  Token(type='ID', value='total', line=3, column=15)\n",
            "\n",
            "VALUE:  +\n",
            "NADA HAVER:  Token(type='OP', value='+', line=3, column=20)\n",
            "\n",
            "VALUE:  price\n",
            "NADA HAVER:  Token(type='ID', value='price', line=3, column=21)\n",
            "\n",
            "VALUE:  *\n",
            "NADA HAVER:  Token(type='OP', value='*', line=3, column=26)\n",
            "\n",
            "VALUE:  quantity\n",
            "NADA HAVER:  Token(type='ID', value='quantity', line=3, column=27)\n",
            "\n",
            "VALUE:  ;\n",
            "NADA HAVER:  Token(type='END', value=';', line=3, column=35)\n",
            "\n",
            "VALUE:  \n",
            "\n",
            "\n",
            "VALUE:          \n",
            "\n",
            "VALUE:  tax\n",
            "NADA HAVER:  Token(type='ID', value='tax', line=4, column=8)\n",
            "\n",
            "VALUE:   \n",
            "\n",
            "VALUE:  :=\n",
            "NADA HAVER:  Token(type='ASSIGN', value=':=', line=4, column=12)\n",
            "\n",
            "VALUE:   \n",
            "\n",
            "VALUE:  price\n",
            "NADA HAVER:  Token(type='ID', value='price', line=4, column=15)\n",
            "\n",
            "VALUE:   \n",
            "\n",
            "VALUE:  *\n",
            "NADA HAVER:  Token(type='OP', value='*', line=4, column=21)\n",
            "\n",
            "VALUE:   \n",
            "\n",
            "VALUE:  5\n",
            "NADA HAVER:  Token(type='NUMBER', value=5, line=4, column=23)\n",
            "\n",
            "VALUE:  ;\n",
            "NADA HAVER:  Token(type='END', value=';', line=4, column=24)\n",
            "\n",
            "VALUE:  \n",
            "\n",
            "\n",
            "VALUE:      \n",
            "\n",
            "VALUE:  ENDIF\n",
            "NADA HAVER:  Token(type='ENDIF', value='ENDIF', line=5, column=4)\n",
            "\n",
            "VALUE:  ;\n",
            "NADA HAVER:  Token(type='END', value=';', line=5, column=9)\n",
            "\n",
            "VALUE:  \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}